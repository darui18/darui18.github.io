<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2026/01/17/hello-world/"/>
    <url>/2026/01/17/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>总结</title>
    <link href="/2026/01/07/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    <url>/2026/01/07/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<h1 id="1-可控视频生成技术路线"><a href="#1-可控视频生成技术路线" class="headerlink" title="1. 可控视频生成技术路线"></a>1. 可控视频生成技术路线</h1><table><thead><tr><th>发表时间</th><th>文章&#x2F;模型名称</th><th>核心创新点 (Key Innovations)</th><th>建议关注点 (调研价值)</th><th>论文&#x2F;项目地址</th></tr></thead><tbody><tr><td>2022.08</td><td>DreamBooth</td><td>唯一标识符绑定：通过微调将特定主体绑定到罕见 Token（如 sks）。</td><td>长效 ID 保持：当零样本方案失效时，作为锁定人物特征的底线方案。</td><td>arXiv</td></tr><tr><td>2023.02</td><td>ControlNet</td><td>可训练副本+零卷积：引入外部控制信号（骨架、深度图），奠定结构可控生成基础。</td><td>信号注入机制：学习如何将外部物理约束（Pose）与扩散模型深度融合。</td><td>arXiv</td></tr><tr><td>2023.07</td><td>AnimateDiff</td><td>动作模块 (Motion Module)：不改基座，插入时间注意力层赋予模型“肌肉记忆”。</td><td>时序连贯性</td><td>arXiv</td></tr><tr><td>2023.08</td><td>IP-Adapter</td><td>解耦交叉注意力路径：独立图像特征路径，实现“画风&#x2F;人物”的轻量化迁移。</td><td>特征解耦：研究在不进行全模型微调下，如何通过文本&#x2F;图像双路注入。</td><td>arXiv</td></tr><tr><td>2023.11</td><td>Animate Anyone</td><td>ReferenceNet (对称 UNet)：像素级细节对齐，大幅提升服饰纹理还原度。</td><td>高保真 ID 还原：调研 Spatial-Attention 机制如何解决“换装”闪烁。</td><td>arXiv</td></tr><tr><td>2023.11</td><td>MagicAnimate</td><td>外观编码器+视频融合：增强跨领域（雕塑、油画）人像驱动的鲁棒性。</td><td>风格泛化能力：观察模型在处理非真人（卡通&#x2F;艺术品）时的稳定性。</td><td>arXiv</td></tr><tr><td>2024.03</td><td>Champ</td><td>3D 形状感知 (SMPL 先验)：引入法线图&#x2F;深度图，解决大幅旋转的“纸片感”。</td><td>空间几何理解：研究 3D 先验如何修正 2D 骨架在遮挡场景下的逻辑错误。</td><td>arXiv</td></tr><tr><td>2024.06</td><td>MimicMotion</td><td>置信度感知引导 (Confidence)：识别不准的 Pose 信号并进行平滑修正。</td><td>抗噪鲁棒性：重点研究手部区域增强 Loss 以及对低质量视频的优化。</td><td>arXiv</td></tr><tr><td>2024.12</td><td>Animate Anyone 2</td><td>环境负荷 (Affordance)：优化人物与背景的物理交互（阴影、接触）。</td><td>真实感进阶：调研“对象引导器”如何处理手抓物体等交互。</td><td>Project</td></tr><tr><td>2025.01</td><td>Wan2.2-Animate</td><td>MoE 架构 + Relighting LoRA：统一动画与替换模式，支持光影重构。</td><td>光影一致性：关注其 Relighting 模块如何让生成人物融入原始场景光照。</td><td>GitHub</td></tr><tr><td>2025.02</td><td>HumanDiT</td><td>前缀潜变量 (Prefix-Latent) + DiT：全 Transformer 架构处理超长视频。</td><td>架构代差：调研 DiT 相比 UNet 在长序列一致性上的优势。</td><td>Project</td></tr><tr><td>2025.05</td><td>Sonic</td><td>位置偏移自适应融合 (PSF)：针对极速运动优化，解决高速拖影。</td><td>极速动效：关注如何利用“运动残差”学习解决画面模糊与长视频飘移。</td><td>arXiv</td></tr><tr><td>2025.10</td><td>One-to-All Animation</td><td>通过将动画生成重构为自监督外扩（Outpainting）任务，实现了在无需空间对齐和无视构图差异的前提下，从单张参考图生成长时序、高保真的角色动作视频。</td><td>它打破了角色动画对参考图与动作姿态必须空间对齐的严苛限制，为实现任意构图输入下的长时序、高保真视频生成提供了工业级的解决方案。</td><td><a href="https://github.com/ssj9596/One-to-All-Animation">https://github.com/ssj9596/One-to-All-Animation</a></td></tr></tbody></table><h1 id="2-技术细节"><a href="#2-技术细节" class="headerlink" title="2. 技术细节"></a>2. 技术细节</h1><h2 id="1-1-SD-1-5"><a href="#1-1-SD-1-5" class="headerlink" title="1.1. SD 1.5"></a>1.1. SD 1.5</h2><h3 id="1-1-1-推荐参考资料"><a href="#1-1-1-推荐参考资料" class="headerlink" title="1.1.1. 推荐参考资料"></a>1.1.1. 推荐参考资料</h3><ul><li>推荐源码：hkproj&#x2F;pytorch-stable-diffusion</li><li>推荐架构图：<a href="https://blog.csdn.net/xd_wjc/article/details/134441396">https://blog.csdn.net/xd_wjc/article/details/134441396</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python">CrossAttDownBlock<br>    x2<br>    &#123;<br>        ResnetBlock2D<br>            GroupNorm<br>            Silu<br>            Conv<br>            + time emb<br>            GroupNorm<br>            Silu<br>            Conv<br>        AttentionBlock2D<br>            GroupNorm<br>            reshape: (batch, channle, H, W) -&gt; (batch, H*W, channle)<br>            attenion Block:<br>                <span class="hljs-variable language_">self</span> attention<br>                cross attention: + text clip<br>                attention FFN<br>    &#125;<br>    DownSample<br></code></pre></td></tr></table></figure><h2 id="1-2-SD-2-1"><a href="#1-2-SD-2-1" class="headerlink" title="1.2. SD 2.1"></a>1.2. SD 2.1</h2><h2 id="1-3-2022-08-DreamBooth"><a href="#1-3-2022-08-DreamBooth" class="headerlink" title="1.3. 2022.08 DreamBooth"></a>1.3. 2022.08 DreamBooth</h2><h2 id="1-4-2023-02-ControlNet"><a href="#1-4-2023-02-ControlNet" class="headerlink" title="1.4. 2023.02 ControlNet"></a>1.4. 2023.02 ControlNet</h2><h3 id="1-4-1-参考资料"><a href="#1-4-1-参考资料" class="headerlink" title="1.4.1. 参考资料"></a>1.4.1. 参考资料</h3><h3 id="1-4-2-原理"><a href="#1-4-2-原理" class="headerlink" title="1.4.2. 原理"></a>1.4.2. 原理</h3><ul><li>克隆 (Trainable Copy)：ControlNet 会复制一个与原有 U-Net 的 Encoder（下采样部分） 和 Middle Block 完全一致的副本。</li><li>冻结 (Locked Copy)：原有的 U-Net 权重被完全锁定（Frozen），不参与梯度更新。</li><li>ControlNet 的 Encoder 每一层输出，都会经过一个 $1 \times 1$ 的<em>零卷积层</em>，然后加到原有 U-Net 对应的 Decoder（上采样部分） 的输入上。</li></ul><h2 id="1-5-2023-07-AnimateDiff"><a href="#1-5-2023-07-AnimateDiff" class="headerlink" title="1.5. 2023.07 AnimateDiff"></a>1.5. 2023.07 AnimateDiff</h2><p><img src="/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/animate_diff.png" alt="alt text"></p><p>Figure 3: Training pipeline of AnimateDiff. AnimateDiff consists of three training stages for the corresponding component modules. Firstly, a domain adapter (Sec. 4.1) is trained to alleviate the negative effects caused by training videos. Secondly, a motion module (Sec. 4.2) is inserted and trained on videos to learn general motion priors. Lastly, MotionLoRA (Sec. 4.3) is trained on a few reference videos to adapt the pre-trained motion module to new motion patterns.</p><h3 id="1-5-1-参考资料"><a href="#1-5-1-参考资料" class="headerlink" title="1.5.1. 参考资料"></a>1.5.1. 参考资料</h3><ul><li>核心源码：<a href="https://github.com/guoyww/AnimateDiff/blob/main/animatediff/models/motion_module.py">https://github.com/guoyww/AnimateDiff/blob/main/animatediff/models/motion_module.py</a></li></ul><h3 id="1-5-2-核心的模块"><a href="#1-5-2-核心的模块" class="headerlink" title="1.5.2. 核心的模块"></a>1.5.2. 核心的模块</h3><ul><li><p>原始的spatial attention：</p><p>  输入状态：$[Batch, \text{Frame}, \text{Channel}, H, W]$（5D 张量） -&gt;  $[Batch* \text{Frame}, H * W, \text{Channel}]$</p></li><li><p>Motion Module attention(无text注入，有position encoding):</p><p>  输入状态: $[Batch, \text{Frame}, \text{Channel}, H, W]$（5D 张量）-&gt;  $[Batch * H * W, \text{Frame}, \text{Channel}]$ + position embading</p></li></ul><h3 id="1-5-3-全Zero初始化，不会导致向后传播的度一致？"><a href="#1-5-3-全Zero初始化，不会导致向后传播的度一致？" class="headerlink" title="1.5.3. 全Zero初始化，不会导致向后传播的度一致？"></a>1.5.3. 全Zero初始化，不会导致向后传播的度一致？</h3><ul><li>只针对最后的proj为0，（见：<a href="https://github.com/guoyww/AnimateDiff/blob/main/animatediff/models/motion_module.py#L77%EF%BC%89%EF%BC%8C%E6%B1%82%E5%AF%BC%E6%97%B6%E4%B8%8D%E4%BC%9A%E5%AF%BC%E8%87%B4%E5%85%A8%E9%9B%B6%EF%BC%9B">https://github.com/guoyww/AnimateDiff/blob/main/animatediff/models/motion_module.py#L77），求导时不会导致全零；</a></li></ul><h3 id="1-5-4-如何生成多余16帧的视频？"><a href="#1-5-4-如何生成多余16帧的视频？" class="headerlink" title="1.5.4. 如何生成多余16帧的视频？"></a>1.5.4. 如何生成多余16帧的视频？</h3><ul><li><p>滑动窗口：</p><p>  窗口 A: 第 1-16 帧</p><p>  窗口 B: 第 9-24 帧（与 A 重叠 8 帧）</p><p>  窗口 C: 第 17-32 帧（与 B 重叠 8 帧）</p></li><li><p>实现细节：<br>  这里有一个常见的误解：滑动窗口不是先预测完前 16 帧的所有 Step，再去预测后 16 帧。真实的实现逻辑是：在每一个去噪步 $t$（例如从 Step 50 到 Step 49）：</p><ol><li>全量输入：算法持有整个视频长度的 Latent（比如 32 帧的 $z_t$）。</li><li>局部处理：<ol><li>取出窗口 A 的 1-16 帧，跑一次 U-Net，得到 $\epsilon_{1-16}$。</li><li>取出窗口 B 的 9-24 帧，跑一次 U-Net，得到 $\epsilon_{9-24}$。</li><li>…以此类推，直到覆盖全长。</li></ol></li><li>全局组装：将所有窗口预测的 $\epsilon$ 按照上述权重融合，拼回成一个 32 帧长度的完整预测值 $\epsilon_{total}$。</li><li>单步更新：使用这个融合后的 $\epsilon_{total}$，根据采样器算法（如 DDIM），统一将 32 帧的 $z_t$ 更新为 $z_{t-1}$。结论：它在每一轮去噪中都执行了这种“局部观察、全局汇总”的操作。这样，第 9 帧在更新到 $t-1$ 时，既参考了它前面 8 帧的运动趋势，也参考了它后面 8 帧的运动趋势。</li></ol></li><li><p>伪代码：</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 伪代码逻辑</span><br>total_noise_pred = torch.zeros_like(full_video_latent)<br>weights_sum = torch.zeros_like(full_video_latent)<br><br><span class="hljs-keyword">for</span> window_indices <span class="hljs-keyword">in</span> context_scheduler:<br>    <span class="hljs-comment"># 提取局部帧</span><br>    latent_in = full_video_latent[:, :, window_indices]<br>    <span class="hljs-comment"># 预测噪声</span><br>    pred = unet(latent_in, timesteps, text_embeddings)<br>    <span class="hljs-comment"># 应用高斯权重并累加</span><br>    w = get_gaussian_weights(<span class="hljs-built_in">len</span>(window_indices))<br>    total_noise_pred[:, :, window_indices] += pred * w<br>    weights_sum[:, :, window_indices] += w<br><br><span class="hljs-comment"># 归一化得到最终预测</span><br>final_noise_pred = total_noise_pred / weights_sum<br></code></pre></td></tr></table></figure></li><li><p>创新点Temporal Pyramid Sampling（时间金字塔采样）</p><ol><li>核心流程：分层预测与共识融合我们可以将你的想法转化为一个两阶段的采样循环：</li><li>第一阶段：全局骨架生成 (Sparse Pass)输入帧索引为 $[0, 2, 4, 6, 8, 10, 12, 14]$。目的：确定视频的宏观运动轨迹。实现：U-Net 在这一步预测出的噪声定义为 $\epsilon_{sparse}$。虽然只输入了 8 帧，但模型会认为这是一个较短但连贯的动作。</li><li>第二阶段：局部细节细化 (Dense Pass)输入帧索引为 $[0, 1, 2, 3, 4, 5, 6, 7]$。目的：填充中间帧的纹理和细微动作。实现：U-Net 预测出的噪声定义为 $\epsilon_{dense}$。</li><li>第三阶段：加权融合 (The Blending)对于重叠的帧（如 0, 2, 4, 6），我们拥有两份预测结果。此时需要进行噪声重组。</li></ol></li></ul><h2 id="1-6-2023-08-IP-Adapter"><a href="#1-6-2023-08-IP-Adapter" class="headerlink" title="1.6. 2023.08 IP-Adapter"></a>1.6. 2023.08 IP-Adapter</h2><p><img src="/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/ip_adapter.png" alt="alt text"><br>Figure 2:The overall architecture of our proposed IP-Adapter with decoupled cross-attention strategy. Only the newly added modules (in red color) are trained while the pretrained text-to-image model is frozen.</p><h3 id="1-6-1-参考资料"><a href="#1-6-1-参考资料" class="headerlink" title="1.6.1. 参考资料"></a>1.6.1. 参考资料</h3><ul><li><a href="https://zhuanlan.zhihu.com/p/1977771872356680834">https://zhuanlan.zhihu.com/p/1977771872356680834</a></li></ul><h3 id="1-6-2-基本原理"><a href="#1-6-2-基本原理" class="headerlink" title="1.6.2. 基本原理"></a>1.6.2. 基本原理</h3><ul><li>参考text注入方式，引入image参考特征注入（Decoupled），经过image与noise的cross attention后，与text特征加权求和得到输出；</li></ul><h2 id="1-7-2023-11-Animate-Anyone"><a href="#1-7-2023-11-Animate-Anyone" class="headerlink" title="1.7. 2023.11 Animate Anyone"></a>1.7. 2023.11 Animate Anyone</h2><p><img src="/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/animate_anyone.png" alt="alt text"></p><h3 id=""><a href="#" class="headerlink" title=""></a></h3><h3 id="1-7-2-基本原理"><a href="#1-7-2-基本原理" class="headerlink" title="1.7.2. 基本原理"></a>1.7.2. 基本原理</h3><ol><li>保持身份一致性<ul><li>引入ControlNet（细节控制）和IP-adapter（总体风格控制, clip提取特征）作为控制信号，输入Reference Image；</li><li>ControlNet的注入方式（）与原始ReferenceNet的注入方式（叠加）不一致：</li><li>注入方式的数学实现<br> 流程假设当前生成帧的特征为 $x \in \mathbb{R}^{B \times L \times C}$，参考图特征为 $w \in \mathbb{R}^{B \times L \times C}$：<ol><li>拼接（Concat）：我们将两者沿序列长度维度拼在一起，形成一个新的上下文环境 $[x, w]$。</li><li>线性映射：$Q &#x3D; x \cdot W_Q$$K &#x3D; [x, w] \cdot W_K$$V &#x3D; [x, w] \cdot W_V$</li><li>计算注意力权重：$Attention(Q, K, V) &#x3D; \text{Softmax}\left(\frac{Q K^T}{\sqrt{d}}\right) V$</li><li>为什么要这么做？通过这种方式，生成的 $Q$ 可以在整个参考图的特征空间（$K$ 和 $V$）里进行全局扫描。即使参考图中人物的手在左边，而生成视频中手移到了右边，Attention 机制也能通过特征匹配找到“手”的纹理，并准确地迁移过去。</li></ol></li></ul></li><li>精准的骨骼控制<ul><li><p>PoseGuider，架构类似Unet的downsample轻量级网络，用来提取OpenPose的特征，与Noise相加，因为每帧的特征和时间序列强相关，没有必要concate；</p></li><li><p>选择“相加”有其核心考量：</p><p>   强位置约束：相加操作能将骨骼的几何位置信息**强制“刻入”**噪声的每一个像素中。这意味着 U-Net 在还没开始进行任何注意力计算之前，其输入数据中就已经包含了明确的肢体边界信号。</p><p>   降低计算量：如果使用拼接，U-Net 第一层卷积的通道数会增加（例如从 4 变 8），这会改变主网络的参数量。通过相加，可以无缝兼容预训练的 Stable Diffusion 权重，且几乎不增加额外的推理开销。</p><p>   保留纹理空间：拼接通常用于需要模型“理解”更多通道信息的场景，而相加则更适合“引导”已有的生成空间，让模型在原有的生成能力基础上，受到骨架坐标的物理约束。</p></li></ul></li><li>时间建模模块</li><li>训练流程<br> 总的来说，训练分为两个主要阶段：<ol><li>第一阶段：图像预训练（Image Pre-training）这一阶段的目标是训练 ReferenceNet 和 Pose Guider，让模型具备在静态下还原人物细节的能力。<ul><li>训练对象：ReferenceNet、Pose Guider 以及主 UNet 的空间注意力层（Spatial-Attention）。</li><li>输入数据：单张人物图像（或是从视频中随机抽取的单帧）。</li><li>任务逻辑：给模型一张人物图（Reference Image）和对应的姿态图（Pose Map）。模型需要在噪声中重建出这张图。</li><li>核心目的：让 ReferenceNet 学习如何提取像素级特征。让 Pose Guider 学习如何将骨架位置与画面对齐。此时不涉及时间模块，模型只需要证明它能完美“复写”参考图的细节。</li></ul></li><li>第二阶段：视频微调（Video Fine-tuning）在模型已经能画出高质量静态图后，引入时间维度，让它学会“连贯性”。<ul><li>训练对象：仅训练或微调 Temporal-Attention（时间模块）。为了保护第一阶段学到的细节还原能力，通常会冻结 ReferenceNet 和 Pose Guider。</li><li>输入数据：连续的视频片段（例如 TikTok 舞蹈数据集，通常切分为 16 帧一组）。任务逻辑：输入第一帧作为参考图。输入后续 $n$ 帧的 Pose 序列。模型需要生成与 Pose 序列对齐、且身份始终与第一帧一致的视频。</li><li>核心目的：让时间模块学习帧与帧之间的平滑过渡。学习如何处理运动产生的遮挡（例如手摆动到背后时，纹理该如何隐藏和恢复）。</li><li>训练中的关键技巧<ol><li>损失函数 (Loss Functions)Animate Anyone 并没有使用非常奇特的 Loss，主要沿用了扩散模型的 $L_2$ 去噪损失。但在某些复现版本中，为了让脸部更像，会额外增加 Face Loss（使用特定的面部检测器剪裁出脸部区域计算损失）。</li><li>采样与数据增强Resolution：通常先在 $256 \times 256$ 分辨率上预热，最后在 $512 \times 512$ 或更高分辨率上微调。Aspect Ratio：由于人物通常是纵向的（9:16），训练数据通常会进行比例裁剪，以适配短视频场景。</li><li>驱动信号的噪声处理在训练时，输入的 Pose 可能会非常完美，但在推理时 OpenPose 提取的信号可能有噪声。因此，训练时有时会给 Pose 图加入轻微的扰动，增强模型的鲁棒性。</li></ol></li></ul></li></ol></li></ol><h2 id="1-8-2023-12-MagicAnimate"><a href="#1-8-2023-12-MagicAnimate" class="headerlink" title="1.8. 2023.12  MagicAnimate"></a>1.8. 2023.12  MagicAnimate</h2><p><img src="/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/MagicAnimate.png" alt="alt text"></p><p>Figure 2: MagicAnimate pipeline. Given a reference image and the target DensePose motion sequence, MagicAnimate employs a video diffusion model and an appearance encoder for temporal modeling and identity preserving, respectively (left panel). To support long video animation, we devise a simple video fusion strategy that produces smooth video transition during inference (right panel).</p><h3 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h3><ol><li>外观编码器<ol><li>常用的是clip编码,但是提取的信息有限,所以使用了类似ControlNet结构;</li><li>与ControlNet不一样的是,使用了Upsample插入信号,能够提供高保真度的结果,但是模型更大;</li><li>DownSample注入方式,是为模型提供更多的信号特征;</li></ol></li><li>OpenPose（骨架）改为 DensePose,DensePose 提供的 3D 先验比 2D 骨架更准确，减少了“手长在背上”这种逻辑错误。</li></ol><h2 id="1-9-2024-03-Champ"><a href="#1-9-2024-03-Champ" class="headerlink" title="1.9. 2024.03 Champ"></a>1.9. 2024.03 Champ</h2><h2 id="1-10-2024-06-MimicMotion"><a href="#1-10-2024-06-MimicMotion" class="headerlink" title="1.10. 2024.06 MimicMotion"></a>1.10. 2024.06 MimicMotion</h2><h2 id="1-11-2024-12-Animate-Anyone-2"><a href="#1-11-2024-12-Animate-Anyone-2" class="headerlink" title="1.11. 2024.12 Animate Anyone 2"></a>1.11. 2024.12 Animate Anyone 2</h2><h2 id="1-12-2025-02-HumanDiT"><a href="#1-12-2025-02-HumanDiT" class="headerlink" title="1.12. 2025.02 HumanDiT"></a>1.12. 2025.02 HumanDiT</h2><h2 id="1-13-2023-12-MagicAnimate"><a href="#1-13-2023-12-MagicAnimate" class="headerlink" title="1.13. 2023.12  MagicAnimate"></a>1.13. 2023.12  MagicAnimate</h2><h3 id="项目地址：https-github-com-ssj9596-One-to-All-Animation"><a href="#项目地址：https-github-com-ssj9596-One-to-All-Animation" class="headerlink" title="项目地址：https://github.com/ssj9596/One-to-All-Animation"></a>项目地址：<a href="https://github.com/ssj9596/One-to-All-Animation">https://github.com/ssj9596/One-to-All-Animation</a></h3><p><a href="https://arxiv.org/html/2511.22940v2/x3.png">https://arxiv.org/html/2511.22940v2/x3.png</a></p><h3 id="创新点-1"><a href="#创新点-1" class="headerlink" title="创新点"></a>创新点</h3><ol><li>unified occluded-input format（Outpainting Preprocess）<br>传统的模型往往通过简单的拼接或 Attention 来注入参考图，这在人体比例不一致时容易崩溃。</li></ol><p>创新点：通过将多样化布局的参考图转化为统一的“遮挡输入（随机mask作为数据）”格式进行训练，模型学会了如何从任意构图（如仅有上半身的参考图）生成出符合驱动姿态的全景动作（如全身跳舞），极大地提升了布局的鲁棒性。</p><ol start="2"><li>身份鲁棒的姿态控制（Identity-Robust Pose Control）<br>在人脸驱动中，如果驱动视频的脸型和参考图不一致，生成结果往往会变形。</li></ol><p>创新点：引入了外观与骨骼解耦的机制，人为制造差异。通过改进 Pose Guider，弱化了姿态信号中隐含的特定人物骨骼结构特征。缓解了人脸姿态的过拟合（Overfitting）问题，确保即使驱动者的脸型较方，而参考图角色脸型较尖，生成的动画依然能保持参考图原有的身份特征。</p><ol start="3"><li>混合参考融合注意力（Hybrid Reference Fusion Attention）<br>为了在不同分辨率和长短不一的视频序列中保持特征一致性。</li></ol><p>创新点：设计了一个专门的 Reference Extractor（参考提取器），利用混合注意力机制（Hybrid Attention）来注入身份信息。它能从各种比例、分辨率（RoPE3D编码driven video，与reference Image 做cross attention时，frame的编码统一为0，因为ref没有frame参考）提取出深层的 ID 语义，支持跨尺度（如从特写参考图生成远景动画）的迁移。</p><ol start="4"><li><p>令牌替换策略（Token Replace Strategy）<br>针对长视频生成的连贯性问题。去噪顺序：</p><ol><li>完成第 1-81 帧的全部去噪迭代。</li><li>提取第 80-81 帧的去噪后 Latent Token。</li><li>将其作为“历史记忆”输入给第 82-162 帧的推理进程。</li><li>开始下一轮去噪。</li></ol></li></ol><p>效果：在生成超长视频时，通过动态替换潜在空间的 Token，保证了长时序下的背景稳定性和人物身份的一致性，减少了视频中途“变脸”或背景闪烁的情况。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Qwen-VL进化</title>
    <link href="/2026/01/02/Qwen-VL%E8%BF%9B%E5%8C%96/"/>
    <url>/2026/01/02/Qwen-VL%E8%BF%9B%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<p>Qwen-VL：<a href="https://arxiv.org/pdf/2308.12966">https://arxiv.org/pdf/2308.12966</a><br>Qwen-V2：<a href="https://arxiv.org/pdf/2409.12191">https://arxiv.org/pdf/2409.12191</a><br>NaViT：<a href="https://arxiv.org/pdf/2307.06304">https://arxiv.org/pdf/2307.06304</a><br>MM-LLMs综述： <a href="https://arxiv.org/pdf/2401.13601">https://arxiv.org/pdf/2401.13601</a><br>Qwen2.5-VL：Qwen2.5 VL！Qwen2.5 VL！Qwen2.5 VL！</p><p>qwen 1~2: <a href="https://zhuanlan.zhihu.com/p/25267823390">https://zhuanlan.zhihu.com/p/25267823390</a><br>qwen3: <a href="https://modelscope.csdn.net/68ef72108867235e1392572a.html">https://modelscope.csdn.net/68ef72108867235e1392572a.html</a><br><img src="https://pica.zhimg.com/v2-67cd12003a709b6003164b7b2869ede8_1440w.jpg" ></p><h1 id="Qwen-VL"><a href="#Qwen-VL" class="headerlink" title="Qwen-VL"></a>Qwen-VL</h1><p>Qwen-VL 是以Qwen-7B Base为主干模型，通过引入视觉感知器（Visual receptor）来增强视觉特征的感知能力。视觉感知器包括一个跟语言模型对齐视觉编码器（visual encoder）和一个位置感知的适配器（position- aware adapter）。套用上面的通用多模态框架，Qwen-VL包括了典型的前3个模块：</p><h3 id="模态编码器（Modality-Encoder）"><a href="#模态编码器（Modality-Encoder）" class="headerlink" title="模态编码器（Modality Encoder）"></a>模态编码器（Modality Encoder）</h3><p>  视觉编码器（visual encoder），只用来编码图片视觉特征。 ViT架构（Vision Transformer），ViT的网络设置和初始化参数使用了OpenCLIP预训练好的ViT-bigG模型。<br>  Qwen-VL 可接受的图像分辨率为 448*448：（W: 448, H: 448， C: 3）。<br>  ViT参数：patch_size : 14 ，channel：1664</p><h3 id="输入投影层（Input-Projector）："><a href="#输入投影层（Input-Projector）：" class="headerlink" title="输入投影层（Input Projector）："></a>输入投影层（Input Projector）：</h3><p>位置感知的适配器（position-aware adapter）Q-former。经过上述ViT处理后，对于 448<em>448 分辨率的图像，生成一个向量维度为1664的长度为1024的序列，使用*<em>2D绝对位置编码</em></em>。为了压缩视觉token的输入长度，Qwen-VL引入了一个Adapter来压缩图像特征。这个Adaper就是一个随机初始化的单层Cross-Attention模块。该模块使用一组可学习的query向量，将来自ViT的图像特征作为Key向量。通过Cross-Attention操作后将视觉特征序列压缩到固定的256长度。</p><h3 id="LLM主干网络（LLM-Backbone）："><a href="#LLM主干网络（LLM-Backbone）：" class="headerlink" title="LLM主干网络（LLM Backbone）："></a>LLM主干网络（LLM Backbone）：</h3><p>Qwen-7B Base 模型</p><h1 id="Qwen-VL2"><a href="#Qwen-VL2" class="headerlink" title="Qwen-VL2"></a>Qwen-VL2</h1><img src="https://pica.zhimg.com/v2-07b8f4f736fc2a56a5f3e632b87d1224_1440w.jpg" />除了主干模型的升级，论文中还提到了一些重要的升级点，总结如下：<h3 id="模态编码层"><a href="#模态编码层" class="headerlink" title="模态编码层"></a>模态编码层</h3><ol><li><p>采用原生动态分辨率：<br>单一分辨率 -&gt; 任意分辨率， Qwen-VL模型输入只接受单一分辨率的图片，Qwen2-VL可输入不同分辨率的图像，避免了Vision数据适配单一分辨率而导致的失真问题。</p></li><li><p>Vision Encoder位置编码：<br>绝对位置编码 -&gt; 相对位置编码，从二维三角位置编码升级到二维RoPE位置编码，能够支持视频、不同分辨率图片等，RoPE对长序列有更好的泛化能力，有利于提升对长序列Vision特征的建模能力</p></li></ol><h3 id="输入投影层"><a href="#输入投影层" class="headerlink" title="输入投影层"></a>输入投影层</h3><p>输入投影层：压缩Vision token + MLP Adapter<br>Qwen2-VL通过原生动态分辨率方法处理的每个图片的token序列是变长的，无法使用Cross-Attention架构做特征压缩处理。Qwen2-VL采用了一种更简单的压缩方法：对空间位置临近的patch 特征做拼接，再经过2层MLP线性变换，这样将原来长度为 n&#x2F;4<br> 的序列 ，最终将压缩后的特征序列输入给LLM模型。</p><h3 id="LLM主体模型位置编码："><a href="#LLM主体模型位置编码：" class="headerlink" title="LLM主体模型位置编码："></a>LLM主体模型位置编码：</h3><ol><li>1D-&gt;3D RoPE，引入多模态旋转位置编码技术（M-RoPE），刻画多模态(时序、高、宽)三维数据。进一步提升对时空数据的建模能力。</li><li>统一多模态数据：<br>单图片 -&gt; 统一图片和视频，统一框架处理图片和视频数据，进一步提升对真实世界认知和理解能力</li><li>训练数据：<br>1.4B -&gt; 1.4T，数据量提升了3个量级，同时数据覆盖了多领域任务</li></ol><h1 id="Qwen-VL3"><a href="#Qwen-VL3" class="headerlink" title="Qwen-VL3"></a>Qwen-VL3</h1><img src="https://i-blog.csdnimg.cn/img_convert/c4f9d1656831bbffa99efb346f3adb47.png" />一是采用 MRoPE-Interleave，原始MRoPE将特征维度按照时间（t）、高度（h)和宽度（w)的顺序分块划分，使得时间信息全部分布在高频维度上。研究团队在 Qwen3-VL 中**采取了 t,h,w 交错分布**的形式，实现对时间，高度和宽度的全频率覆盖，这样更加鲁棒的位置编码能够保证模型在图片理解能力相当的情况下，提升对长视频的理解能力；<p>二是引入 DeepStack 技术，融合 ViT 多层次特征，提升视觉细节捕捉能力和图文对齐精度；沿用** DeepStack **的核心思想，将以往多模态大模型（LMM）单层输入视觉tokens的范式，改为在大型语言模型 (LLM) 的多层中进行注入。这种多层注入方式旨在实现更精细化的视觉理解。<br>在此基础上，官方进一步优化了视觉特征 token 化的策略。具体而言，Qwen团队将来自 ViT 不同层的视觉特征进行 token 化，并以此作为视觉输入。这种设计能够有效保留从底层（low-level）到高层（high-level）的丰富视觉信息。实验结果表明，该方法在多种视觉理解任务上均展现出显著的性能提升。</p><p>三是将原有的视频时序建模机制 T-RoPE 升级为 文本时间戳对齐机制。该机采用“时间戳-视频帧”交错的输入形式，实现帧级别的时间信息与视觉内容的细粒度对齐。同时，模型原生支持“秒数”与“时:分:秒”（HMS）两种时间输出格式。这一改进显著提升了模型对视频中动作、事件的语义感知与时间定位精度，使其在复杂时序推理任务——如事件定位、动作边界检测、跨模态时间问答等——中表现更稳健、响应更精准。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>原理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>VLM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>认知觉醒</title>
    <link href="/2025/12/20/%E8%AE%A4%E7%9F%A5%E8%A7%89%E9%86%92/"/>
    <url>/2025/12/20/%E8%AE%A4%E7%9F%A5%E8%A7%89%E9%86%92/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>读书笔记</category>
      
      <category>社科</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>VLM / VLA 架构对比</title>
    <link href="/2025/12/20/VLM-VLA-%E6%9E%B6%E6%9E%84%E5%AF%B9%E6%AF%94/"/>
    <url>/2025/12/20/VLM-VLA-%E6%9E%B6%E6%9E%84%E5%AF%B9%E6%AF%94/</url>
    
    <content type="html"><![CDATA[<h1 id="VLM架构"><a href="#VLM架构" class="headerlink" title="VLM架构"></a>VLM架构</h1><h2 id="参考资料：https-arxiv-org-pdf-2401-13601"><a href="#参考资料：https-arxiv-org-pdf-2401-13601" class="headerlink" title="参考资料：https://arxiv.org/pdf/2401.13601"></a>参考资料：<a href="https://arxiv.org/pdf/2401.13601">https://arxiv.org/pdf/2401.13601</a></h2>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>ReinforceLearning</title>
    <link href="/2025/12/20/ReinforceLearning/"/>
    <url>/2025/12/20/ReinforceLearning/</url>
    
    <content type="html"><![CDATA[<p>#策略梯度（Policy Gradient）推导</p><ol><li><p>目标函数<br>最大化轨迹 $\tau$ 的期望回报 $J(\theta)$：<br>$$<br> \max J(\theta) &#x3D; \mathbb{E}<em>{\tau \sim \pi</em>\theta(\tau)} [R(\tau)] &#x3D; \int \pi_\theta(\tau) R(\tau) d\tau \<br> &#x3D; \int P(s_0) \prod_{t&#x3D;0}^{T-1} \pi_\theta(a_t|s_t) P(s_{t+1}|s_t, a_t) R(\tau) d\tau \<br>$$<br>其中：  </p><ul><li>$\tau$ 是一个序列：$(s_0, a_0, s_1, a_1, \dots)$。  </li><li>$\pi_\theta(\tau)$ 是策略网络生成该轨迹的概率。  </li><li>$R(\tau)$ 是该轨迹的总奖励。</li></ul></li><li><p>梯度推导（Log-Derivative Trick）<br>对 $J(\theta)$ 求导。由于 $R(\tau)$ 与 $\theta$ 无关（环境给的），导数只作用于概率密度函数：<br>$$<br>\nabla_\theta J(\theta) &#x3D; \int \nabla_\theta \pi_\theta(\tau) R(\tau) d\tau \<br>&#x3D; \int \nabla_\theta (P(s_0) \prod_{t&#x3D;0}^{T-1} \pi_\theta(a_t|s_t) P(s_{t+1}|s_t, a_t) R(\tau) d\tau) \<br>&#x3D;  \int P(s_0) \sum_{t&#x3D;0}^{T-1}\prod_{t&#x3D;0,t!&#x3D;v}^{T-1} \pi_\theta(a_t|s_t) \nabla_\theta(\pi_\theta(a_v|s_v)) P(s_{t+1}|s_t, a_t) R(\tau) d\tau \quad \text{\small 多元求导公式}\<br>&#x3D; \int P(s_0) \sum_{t&#x3D;0}^{T-1}\prod_{t&#x3D;0,t!&#x3D;v}^{T-1} \pi_\theta(a_t|s_t) \pi_\theta(a_v|s_v)\nabla_\theta \ln(\pi_\theta(a_v|s_v)) P(s_{t+1}|s_t, a_t) R(\tau) d\tau \<br> &#x3D; \int P(s_0) \prod_{t&#x3D;0}^{T-1} \pi_\theta(a_t|s_t) P(s_{t+1}|s_t, a_t) R(\tau) \sum_{t&#x3D;0}^{T-1}\nabla_\theta \ln(\pi_\theta(a_v|s_v))d\tau \<br> &#x3D; \int \pi_\theta(\tau) \nabla_\theta \ln \pi_\theta(\tau) R(\tau) d\tau<br>$$<br>无法直接对这个积分进行采样，因为 $\nabla_\theta \pi_\theta$ 不是一个概率分布。于是引入 对数导数技巧（Log-Derivative Trick）：因为 $\nabla \ln x &#x3D; \frac{\nabla x}{x}$，所以 $\nabla \pi &#x3D; \pi \nabla \ln \pi$。代入公式：<br>$$<br>\nabla_\theta J(\theta) &#x3D; \int \pi_\theta(\tau) \nabla_\theta \ln \pi_\theta(\tau) R(\tau) d\tau<br>$$<br>变换后，它重新变成了一个期望的形式：<br>$$\nabla_\theta J(\theta) &#x3D; \mathbb{E}<em>{\tau \sim \pi</em>\theta(\tau)} [\nabla_\theta \ln \pi_\theta(\tau) R(\tau)]$$</p></li><li><p>展开轨迹概率轨迹的概率<br>$\pi_\theta(\tau)$ 取决于状态转移和策略：<br>$$\pi_\theta(\tau) &#x3D; P(s_0) \prod_{t&#x3D;0}^{T-1} \pi_\theta(a_t|s_t) P(s_{t+1}|s_t, a_t)$$<br>取对数后，不含参数 $\theta$ 的环境项（状态转移概率）求导后全部消失了：<br>$$\nabla_\theta \ln \pi_\theta(\tau) &#x3D; \sum_{t&#x3D;0}^{T} \nabla_\theta \ln \pi_\theta(a_t|s_t)$$</p></li><li><p>最终公式 (REINFORCE)<br>将展开结果代回，得到最经典的策略梯度公式：<br>$$\nabla_\theta J(\theta) \approx \frac{1}{N} \sum_{i&#x3D;1}^{N} \left( \sum_{t&#x3D;0}^{T} \nabla_\theta \ln \pi_\theta(a_{i,t}|s_{i,t}) \right) R(\tau_i)$$</p></li><li><p>直观理解：<br>它在做什么？这个公式的物理意义非常直观，可以拆解为三部分：<br>$\nabla_\theta \ln \pi_\theta(a_t|s_t)$：这部分决定了更新的方向——即如何增加动作 $a_t$ 出现的概率。<br>$R(\tau)$：这是步长和权重。如果 $R$ 是正数，这一步动作的概率会被推高。如果 $R$ 是负数，这一步动作的概率会被压低。<br>期望符号：通过大量采样，抵消环境随机性带来的噪声。</p></li></ol><p> PPO → DPO → GRPO</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>FP方程下的Flow Matching和Diffusion</title>
    <link href="/2025/12/20/Diffusion/"/>
    <url>/2025/12/20/Diffusion/</url>
    
    <content type="html"><![CDATA[<p>贝叶斯方式<br>已知 $p(x_t|x_{t-1})$<br>希望求解 $p(x_{t-1}|x_t)$</p><p>SDE</p><ol><li>正向SDE</li><li>反向SDE （求解过程）</li><li>求解 $\nabla_x \log p(x_t)$ ，使用 $\nabla_{x_t}\log(x_t|x_0)$ 作为替代</li></ol><p>SDE -&gt; ODE<br>通过FP方程，得到DDIM</p><p>加噪数学公式为：<br>    $x_t &#x3D; \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon$</p><p>加噪代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SimpleDiffusion</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, timesteps=<span class="hljs-number">1000</span>, beta_start=<span class="hljs-number">1e-4</span>, beta_end=<span class="hljs-number">0.02</span></span>):<br>        <span class="hljs-variable language_">self</span>.timesteps = timesteps<br>        <br>        <span class="hljs-comment"># 1. 定义线性噪声调度 beta</span><br>        <span class="hljs-variable language_">self</span>.betas = torch.linspace(beta_start, beta_end, timesteps)<br>        <br>        <span class="hljs-comment"># 2. 计算 alphas = 1 - betas</span><br>        <span class="hljs-variable language_">self</span>.alphas = <span class="hljs-number">1.0</span> - <span class="hljs-variable language_">self</span>.betas<br>        <br>        <span class="hljs-comment"># 3. 计算 alphas_cumprod (即公式里的 \bar&#123;\alpha&#125;_t)</span><br>        <span class="hljs-variable language_">self</span>.alphas_cumprod = torch.cumprod(<span class="hljs-variable language_">self</span>.alphas, dim=<span class="hljs-number">0</span>)<br>        <br>        <span class="hljs-comment"># 4. 预计算用于加噪的系数</span><br>        <span class="hljs-comment"># sqrt(\bar&#123;\alpha&#125;_t)</span><br>        <span class="hljs-variable language_">self</span>.sqrt_alphas_cumprod = torch.sqrt(<span class="hljs-variable language_">self</span>.alphas_cumprod)<br>        <span class="hljs-comment"># sqrt(1 - \bar&#123;\alpha&#125;_t)</span><br>        <span class="hljs-variable language_">self</span>.sqrt_one_minus_alphas_cumprod = torch.sqrt(<span class="hljs-number">1.0</span> - <span class="hljs-variable language_">self</span>.alphas_cumprod)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_extract_coef</span>(<span class="hljs-params">self, a, t, x_shape</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;提取指定时间步 t 的系数，并调整维度以匹配图像张量&quot;&quot;&quot;</span><br>        batch_size = t.shape[<span class="hljs-number">0</span>]<br>        out = a.gather(-<span class="hljs-number">1</span>, t.cpu())<br>        <span class="hljs-keyword">return</span> out.reshape(batch_size, *((<span class="hljs-number">1</span>,) * (<span class="hljs-built_in">len</span>(x_shape) - <span class="hljs-number">1</span>))).to(t.device)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">q_sample</span>(<span class="hljs-params">self, x_start, t, noise=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;前向加噪过程: 根据 x_0 和 t 直接生成 x_t&quot;&quot;&quot;</span><br>        <span class="hljs-keyword">if</span> noise <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            noise = torch.randn_like(x_start)<br><br>        <span class="hljs-comment"># 提取系数</span><br>        sqrt_alphas_cumprod_t = <span class="hljs-variable language_">self</span>.get_extract_coef(<span class="hljs-variable language_">self</span>.sqrt_alphas_cumprod, t, x_start.shape)<br>        sqrt_one_minus_alphas_cumprod_t = <span class="hljs-variable language_">self</span>.get_extract_coef(<span class="hljs-variable language_">self</span>.sqrt_one_minus_alphas_cumprod, t, x_start.shape)<br><br>        <span class="hljs-comment"># 核心公式计算</span><br>        <span class="hljs-keyword">return</span> sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>原理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Diffusion</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>速度场下的Flow Matching和Diffusion</title>
    <link href="/2025/12/20/Flow%20Matching%E4%B8%8EDiffusion%E7%9A%84%E5%B7%AE%E5%88%AB/"/>
    <url>/2025/12/20/Flow%20Matching%E4%B8%8EDiffusion%E7%9A%84%E5%B7%AE%E5%88%AB/</url>
    
    <content type="html"><![CDATA[<h2 id="1-连续性方程"><a href="#1-连续性方程" class="headerlink" title="1. 连续性方程"></a>1. 连续性方程</h2><h2 id="2-Flow-matching"><a href="#2-Flow-matching" class="headerlink" title="2. Flow matching"></a>2. Flow matching</h2><h2 id="3-Condition-Flow-Matching"><a href="#3-Condition-Flow-Matching" class="headerlink" title="3. Condition Flow Matching"></a>3. Condition Flow Matching</h2><h2 id="4-具体路径"><a href="#4-具体路径" class="headerlink" title="4. 具体路径"></a>4. 具体路径</h2><h2 id=""><a href="#" class="headerlink" title=""></a></h2><ol start="3"><li>直观理解：导航系统的例子想象你在开车从 A（$x_0$）去 B（$x_1$）。训练阶段： 我们观察成千上万次从 A 到 B 的行驶记录。每一时刻，车速都是由起点和终点决定的。推理阶段： 你是一台自动驾驶电脑。现在你被扔在了路中间的某个点 $x_t$。消除 $x_0$ 的意义： 你的传感器只能看到你现在的坐标 $x_t$。如果你不知道你当初是从哪个具体的车库（$x_0$）出来的，你该怎么走？通过推导出的公式（如 VP 路径的公式），我们可以把“当初从哪来”的信息，转化为“现在在哪里”和“最终去哪里”的关系。公式中的 $x_t$ 项其实就代表了“你当前的位置”，它隐含了路径演化至今的状态。</li></ol>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>原理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Diffusion</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>flow matching与retify flow的区别是什么</title>
    <link href="/2025/12/20/FlowMatching%20With%20Rectify%20FM/"/>
    <url>/2025/12/20/FlowMatching%20With%20Rectify%20FM/</url>
    
    <content type="html"><![CDATA[<p>flow matching与retify flow的区别是什么</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>原理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Diffusion</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Transformer</title>
    <link href="/2025/12/20/Transformer/"/>
    <url>/2025/12/20/Transformer/</url>
    
    <content type="html"><![CDATA[<h2 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h2><h3 id="Attentino"><a href="#Attentino" class="headerlink" title="Attentino"></a>Attentino</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Attention</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.dim = dim<br>        <span class="hljs-variable language_">self</span>.qkv = nn.Linear(dim, dim * <span class="hljs-number">3</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, mask=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-comment"># 1. 线性变换后解包</span><br>        <span class="hljs-comment"># qkv_res 形状: (batch, seq_len, dim * 3)</span><br>        qkv_res = <span class="hljs-variable language_">self</span>.qkv(x)<br>        <br>        <span class="hljs-comment"># 拆分为 q, k, v (每个形状: batch, seq_len, dim)</span><br>        q, k, v = torch.chunk(qkv_res, <span class="hljs-number">3</span>, dim=-<span class="hljs-number">1</span>)<br><br>        <span class="hljs-comment"># 2. 计算打分 (Scalable Dot-Product)</span><br>        <span class="hljs-comment"># k.transpose(-2, -1) 确保维度变为 (batch, dim, seq_len)</span><br>        <span class="hljs-comment"># d_k 通常取 head_dim，这里简化为 dim</span><br>        d_k = q.size(-<span class="hljs-number">1</span>)<br>        attn_logits = torch.matmul(q, k.transpose(-<span class="hljs-number">2</span>, -<span class="hljs-number">1</span>)) / (d_k ** <span class="hljs-number">0.5</span>)<br><br>        <span class="hljs-comment"># 3. Mask 处理</span><br>        <span class="hljs-keyword">if</span> mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-comment"># 建议使用 masked_fill 替代直接相加，更稳定</span><br>            attn_logits = attn_logits.masked_fill(mask == <span class="hljs-number">0</span>, <span class="hljs-built_in">float</span>(<span class="hljs-string">&#x27;-inf&#x27;</span>))<br><br>        <span class="hljs-comment"># 4. Softmax 与 加权求和</span><br>        score = F.softmax(attn_logits, dim=-<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> torch.matmul(score, v)<br></code></pre></td></tr></table></figure><h3 id="Multihead-Attention"><a href="#Multihead-Attention" class="headerlink" title="Multihead Attention"></a>Multihead Attention</h3><h3 id="Multil-Query-Attention"><a href="#Multil-Query-Attention" class="headerlink" title="Multil Query Attention"></a>Multil Query Attention</h3><h3 id="Multi-Group-Attention"><a href="#Multi-Group-Attention" class="headerlink" title="Multi Group Attention"></a>Multi Group Attention</h3><h2 id="Position-Embading"><a href="#Position-Embading" class="headerlink" title="Position Embading"></a>Position Embading</h2><h3 id="RoPE"><a href="#RoPE" class="headerlink" title="RoPE"></a>RoPE</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">precompute_freqs_cis</span>(<span class="hljs-params">dim: <span class="hljs-built_in">int</span>, end: <span class="hljs-built_in">int</span>, theta: <span class="hljs-built_in">float</span> = <span class="hljs-number">10000.0</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    预计算旋转频率</span><br><span class="hljs-string">    dim: 每个 Head 的维度 (head_dim)</span><br><span class="hljs-string">    end: 最大序列长度 (max_seq_len)</span><br><span class="hljs-string">    theta: 基数，控制旋转速度</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 1. 计算频率步长: theta^&#123;-2i/d&#125;</span><br>    <span class="hljs-comment"># 每一对维度共享一个频率，所以只算 dim // 2 个</span><br>    freqs = <span class="hljs-number">1.0</span> / (theta ** (torch.arange(<span class="hljs-number">0</span>, dim, <span class="hljs-number">2</span>)[: (dim // <span class="hljs-number">2</span>)].<span class="hljs-built_in">float</span>() / dim))<br>    <br>    <span class="hljs-comment"># 2. 生成位置索引 t = [0, 1, 2, ..., end-1]</span><br>    t = torch.arange(end, device=freqs.device)<br>    <br>    <span class="hljs-comment"># 3. 计算相位矩阵: 每个位置对应的每个维度的弧度</span><br>    <span class="hljs-comment"># shape: [end, dim // 2]</span><br>    freqs = torch.outer(t, freqs).<span class="hljs-built_in">float</span>()<br>    <br>    <span class="hljs-comment"># 4. 转换为复数坐标形式: cos(theta) + i*sin(theta)</span><br>    <span class="hljs-comment"># 这在数学上等价于旋转矩阵</span><br>    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)<br>    <span class="hljs-keyword">return</span> freqs_cis<br><br><span class="hljs-comment"># Version 1： 利用复数乘法的性质（ $(a+bi)(c+di)$ ）来高效实现旋转。</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">reshape_for_broadcast</span>(<span class="hljs-params">freqs_cis: torch.Tensor, x: torch.Tensor</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;调整 freqs_cis 形状以匹配 x 的维度 (batch, head, seq_len, dim)&quot;&quot;&quot;</span><br>    ndim = x.ndim<br>    <span class="hljs-keyword">assert</span> <span class="hljs-number">0</span> &lt;= <span class="hljs-number">1</span> &lt; ndim<br>    <span class="hljs-keyword">assert</span> freqs_cis.shape == (x.shape[<span class="hljs-number">1</span>], x.shape[-<span class="hljs-number">1</span>])<br>    shape = [d <span class="hljs-keyword">if</span> i == <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> i == ndim - <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">1</span> <span class="hljs-keyword">for</span> i, d <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(x.shape)]<br>    <span class="hljs-keyword">return</span> freqs_cis.view(*shape)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">apply_rotary_emb</span>(<span class="hljs-params">xq: torch.Tensor, xk: torch.Tensor, freqs_cis: torch.Tensor</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    xq, xk: [batch, seq_len, n_heads, head_dim]</span><br><span class="hljs-string">    freqs_cis: [seq_len, head_dim // 2]</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 1. 将实数向量转为复数对</span><br>    <span class="hljs-comment"># [batch, seq_len, n_heads, head_dim//2, 2] -&gt; 转化为复数</span><br>    xq_ = torch.view_as_complex(xq.<span class="hljs-built_in">float</span>().reshape(*xq.shape[:-<span class="hljs-number">1</span>], -<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))<br>    xk_ = torch.view_as_complex(xk.<span class="hljs-built_in">float</span>().reshape(*xk.shape[:-<span class="hljs-number">1</span>], -<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))<br><br>    <span class="hljs-comment"># 2. 准备频率矩阵</span><br>    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)<br><br>    <span class="hljs-comment"># 3. 执行复数乘法（即执行旋转）并转回实数</span><br>    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(<span class="hljs-number">3</span>)<br>    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(<span class="hljs-number">3</span>)<br><br>    <span class="hljs-keyword">return</span> xq_out.type_as(xq), xk_out.type_as(xk)<br><br><span class="hljs-comment"># Version 2： 直接使用实数矩阵操作。</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">rotate_half</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;将 [x1, x2, x3, x4] 变为 [-x2, x1, -x4, x3]&quot;&quot;&quot;</span><br>    x1 = x[..., : x.shape[-<span class="hljs-number">1</span>] // <span class="hljs-number">2</span>]<br>    x2 = x[..., x.shape[-<span class="hljs-number">1</span>] // <span class="hljs-number">2</span> :]<br>    <span class="hljs-keyword">return</span> torch.cat((-x2, x1), dim=-<span class="hljs-number">1</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">apply_rotary_pos_emb</span>(<span class="hljs-params">q, k, cos, sin</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    q, k: [batch, n_heads, seq_len, head_dim]</span><br><span class="hljs-string">    cos, sin: [seq_len, head_dim]</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-comment"># 准备 cos 和 sin，并扩展维度以匹配 x (b, s, d)</span><br>    <span class="hljs-comment"># RoPE 通常将 cos/sin 复制一份，使得维度变成 (s, d)</span><br>    cos = torch.cos(freqs).repeat(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># (s, d)</span><br>    sin = torch.sin(freqs).repeat(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># (s, d)</span><br><br>    q_embed = (q * cos) + (rotate_half(q) * sin)<br>    k_embed = (k * cos) + (rotate_half(k) * sin)<br>    <span class="hljs-keyword">return</span> q_embed, k_embed<br><br><br><span class="hljs-comment">## 3D RoPE</span><br><span class="hljs-comment">## 3D-RoPE 的实现逻辑是 1D-RoPE 的高维演进。它的核心在于维度解耦：将一个向量切分为三段，分别在时间（T）、高度（H）、宽度（W）三个轴上独立应用旋转。</span><br><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">rotate_half</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;将特征对半拆分并交换，构造旋转效果&quot;&quot;&quot;</span><br>    x1, x2 = x.chunk(<span class="hljs-number">2</span>, dim=-<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> torch.cat((-x2, x1), dim=-<span class="hljs-number">1</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">apply_3d_rope</span>(<span class="hljs-params">q, k, freqs_t, freqs_h, freqs_w</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    q, k: [B, L, H, D]  (D 是 head_dim)</span><br><span class="hljs-string">    freqs_t, freqs_h, freqs_w: [L, D//3] 对应三个维度的 cos/sin 频率</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    d_part = q.shape[-<span class="hljs-number">1</span>] // <span class="hljs-number">3</span><br>    <br>    <span class="hljs-comment"># 1. 拆分 Query 和 Key 的维度</span><br>    q_t, q_h, q_w = q.split(d_part, dim=-<span class="hljs-number">1</span>)<br>    k_t, k_h, k_w = k.split(d_part, dim=-<span class="hljs-number">1</span>)<br>    <br>    <span class="hljs-comment"># 2. 定义局部应用 RoPE 的函数</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">apply_rope_to_part</span>(<span class="hljs-params">x, freqs</span>):<br>        <span class="hljs-comment"># freqs 包含拼接好的 cos 和 sin</span><br>        cos, sin = freqs.chunk(<span class="hljs-number">2</span>, dim=-<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> (x * cos) + (rotate_half(x) * sin)<br><br>    <span class="hljs-comment"># 3. 三个轴并行旋转</span><br>    q_out = torch.cat([<br>        apply_rope_to_part(q_t, freqs_t),<br>        apply_rope_to_part(q_h, freqs_h),<br>        apply_rope_to_part(q_w, freqs_w)<br>    ], dim=-<span class="hljs-number">1</span>)<br>    <br>    k_out = torch.cat([<br>        apply_rope_to_part(k_t, freqs_t),<br>        apply_rope_to_part(k_h, freqs_h),<br>        apply_rope_to_part(k_w, freqs_w)<br>    ], dim=-<span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">return</span> q_out, k_out<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>经典算法</category>
      
      <category>原理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Diffusion</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>常见问题记录</title>
    <link href="/2025/12/20/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"/>
    <url>/2025/12/20/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<h1 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h1><h3 id="Attention-1"><a href="#Attention-1" class="headerlink" title="Attention"></a>Attention</h3><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Transformer%2C_full_architecture.png/1280px-Transformer%2C_full_architecture.png" alt="图片alt" title="Attention 架构"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Attention</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.dim = dim<br>        <span class="hljs-variable language_">self</span>.qkv = nn.Linear(dim, dim * <span class="hljs-number">3</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, mask=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-comment"># 1. 线性变换后解包</span><br>        <span class="hljs-comment"># qkv_res 形状: (batch, seq_len, dim * 3)</span><br>        qkv_res = <span class="hljs-variable language_">self</span>.qkv(x)<br>        <br>        <span class="hljs-comment"># 拆分为 q, k, v (每个形状: batch, seq_len, dim)</span><br>        q, k, v = torch.chunk(qkv_res, <span class="hljs-number">3</span>, dim=-<span class="hljs-number">1</span>)<br><br>        <span class="hljs-comment"># 2. 计算打分 (Scalable Dot-Product)</span><br>        <span class="hljs-comment"># k.transpose(-2, -1) 确保维度变为 (batch, dim, seq_len)</span><br>        <span class="hljs-comment"># d_k 通常取 head_dim，这里简化为 dim</span><br>        d_k = q.size(-<span class="hljs-number">1</span>)<br>        attn_logits = torch.matmul(q, k.transpose(-<span class="hljs-number">2</span>, -<span class="hljs-number">1</span>)) / (d_k ** <span class="hljs-number">0.5</span>)<br><br>        <span class="hljs-comment"># 3. Mask 处理</span><br>        <span class="hljs-keyword">if</span> mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-comment"># 建议使用 masked_fill 替代直接相加，更稳定</span><br>            attn_logits = attn_logits.masked_fill(mask == <span class="hljs-number">0</span>, <span class="hljs-built_in">float</span>(<span class="hljs-string">&#x27;-inf&#x27;</span>))<br><br>        <span class="hljs-comment"># 4. Softmax 与 加权求和</span><br>        score = F.softmax(attn_logits, dim=-<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> torch.matmul(score, v)<br></code></pre></td></tr></table></figure><h3 id="Multihead-Attention"><a href="#Multihead-Attention" class="headerlink" title="Multihead Attention"></a>Multihead Attention</h3><h3 id="Multil-Query-Attention"><a href="#Multil-Query-Attention" class="headerlink" title="Multil Query Attention"></a>Multil Query Attention</h3><h3 id="Multi-Group-Attention"><a href="#Multi-Group-Attention" class="headerlink" title="Multi Group Attention"></a>Multi Group Attention</h3><h2 id="Position-Embading"><a href="#Position-Embading" class="headerlink" title="Position Embading"></a>Position Embading</h2><h3 id="RoPE"><a href="#RoPE" class="headerlink" title="RoPE"></a>RoPE</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">precompute_freqs_cis</span>(<span class="hljs-params">dim: <span class="hljs-built_in">int</span>, end: <span class="hljs-built_in">int</span>, theta: <span class="hljs-built_in">float</span> = <span class="hljs-number">10000.0</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    预计算旋转频率</span><br><span class="hljs-string">    dim: 每个 Head 的维度 (head_dim)</span><br><span class="hljs-string">    end: 最大序列长度 (max_seq_len)</span><br><span class="hljs-string">    theta: 基数，控制旋转速度</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 1. 计算频率步长: theta^&#123;-2i/d&#125;</span><br>    <span class="hljs-comment"># 每一对维度共享一个频率，所以只算 dim // 2 个</span><br>    freqs = <span class="hljs-number">1.0</span> / (theta ** (torch.arange(<span class="hljs-number">0</span>, dim, <span class="hljs-number">2</span>)[: (dim // <span class="hljs-number">2</span>)].<span class="hljs-built_in">float</span>() / dim))<br>    <br>    <span class="hljs-comment"># 2. 生成位置索引 t = [0, 1, 2, ..., end-1]</span><br>    t = torch.arange(end, device=freqs.device)<br>    <br>    <span class="hljs-comment"># 3. 计算相位矩阵: 每个位置对应的每个维度的弧度</span><br>    <span class="hljs-comment"># shape: [end, dim // 2]</span><br>    freqs = torch.outer(t, freqs).<span class="hljs-built_in">float</span>()<br>    <br>    <span class="hljs-comment"># 4. 转换为复数坐标形式: cos(theta) + i*sin(theta)</span><br>    <span class="hljs-comment"># 这在数学上等价于旋转矩阵</span><br>    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)<br>    <span class="hljs-keyword">return</span> freqs_cis<br><br><span class="hljs-comment"># Version 1： 利用复数乘法的性质（ $(a+bi)(c+di)$ ）来高效实现旋转。</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">reshape_for_broadcast</span>(<span class="hljs-params">freqs_cis: torch.Tensor, x: torch.Tensor</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;调整 freqs_cis 形状以匹配 x 的维度 (batch, head, seq_len, dim)&quot;&quot;&quot;</span><br>    ndim = x.ndim<br>    <span class="hljs-keyword">assert</span> <span class="hljs-number">0</span> &lt;= <span class="hljs-number">1</span> &lt; ndim<br>    <span class="hljs-keyword">assert</span> freqs_cis.shape == (x.shape[<span class="hljs-number">1</span>], x.shape[-<span class="hljs-number">1</span>])<br>    shape = [d <span class="hljs-keyword">if</span> i == <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> i == ndim - <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">1</span> <span class="hljs-keyword">for</span> i, d <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(x.shape)]<br>    <span class="hljs-keyword">return</span> freqs_cis.view(*shape)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">apply_rotary_emb</span>(<span class="hljs-params">xq: torch.Tensor, xk: torch.Tensor, freqs_cis: torch.Tensor</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    xq, xk: [batch, seq_len, n_heads, head_dim]</span><br><span class="hljs-string">    freqs_cis: [seq_len, head_dim // 2]</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 1. 将实数向量转为复数对</span><br>    <span class="hljs-comment"># [batch, seq_len, n_heads, head_dim//2, 2] -&gt; 转化为复数</span><br>    xq_ = torch.view_as_complex(xq.<span class="hljs-built_in">float</span>().reshape(*xq.shape[:-<span class="hljs-number">1</span>], -<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))<br>    xk_ = torch.view_as_complex(xk.<span class="hljs-built_in">float</span>().reshape(*xk.shape[:-<span class="hljs-number">1</span>], -<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))<br><br>    <span class="hljs-comment"># 2. 准备频率矩阵</span><br>    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)<br><br>    <span class="hljs-comment"># 3. 执行复数乘法（即执行旋转）并转回实数</span><br>    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(<span class="hljs-number">3</span>)<br>    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(<span class="hljs-number">3</span>)<br><br>    <span class="hljs-keyword">return</span> xq_out.type_as(xq), xk_out.type_as(xk)<br><br><span class="hljs-comment"># Version 2： 直接使用实数矩阵操作。</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">rotate_half</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;将 [x1, x2, x3, x4] 变为 [-x2, x1, -x4, x3]&quot;&quot;&quot;</span><br>    x1 = x[..., : x.shape[-<span class="hljs-number">1</span>] // <span class="hljs-number">2</span>]<br>    x2 = x[..., x.shape[-<span class="hljs-number">1</span>] // <span class="hljs-number">2</span> :]<br>    <span class="hljs-keyword">return</span> torch.cat((-x2, x1), dim=-<span class="hljs-number">1</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">apply_rotary_pos_emb</span>(<span class="hljs-params">q, k, cos, sin</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    q, k: [batch, n_heads, seq_len, head_dim]</span><br><span class="hljs-string">    cos, sin: [seq_len, head_dim]</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-comment"># 准备 cos 和 sin，并扩展维度以匹配 x (b, s, d)</span><br>    <span class="hljs-comment"># RoPE 通常将 cos/sin 复制一份，使得维度变成 (s, d)</span><br>    cos = torch.cos(freqs).repeat(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># (s, d)</span><br>    sin = torch.sin(freqs).repeat(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># (s, d)</span><br><br>    q_embed = (q * cos) + (rotate_half(q) * sin)<br>    k_embed = (k * cos) + (rotate_half(k) * sin)<br>    <span class="hljs-keyword">return</span> q_embed, k_embed<br><br><br><span class="hljs-comment">## 3D RoPE</span><br><span class="hljs-comment">## 3D-RoPE 的实现逻辑是 1D-RoPE 的高维演进。它的核心在于维度解耦：将一个向量切分为三段，分别在时间（T）、高度（H）、宽度（W）三个轴上独立应用旋转。</span><br><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">rotate_half</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;将特征对半拆分并交换，构造旋转效果&quot;&quot;&quot;</span><br>    x1, x2 = x.chunk(<span class="hljs-number">2</span>, dim=-<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> torch.cat((-x2, x1), dim=-<span class="hljs-number">1</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">apply_3d_rope</span>(<span class="hljs-params">q, k, freqs_t, freqs_h, freqs_w</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    q, k: [B, L, H, D]  (D 是 head_dim)</span><br><span class="hljs-string">    freqs_t, freqs_h, freqs_w: [L, D//3] 对应三个维度的 cos/sin 频率</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    d_part = q.shape[-<span class="hljs-number">1</span>] // <span class="hljs-number">3</span><br>    <br>    <span class="hljs-comment"># 1. 拆分 Query 和 Key 的维度</span><br>    q_t, q_h, q_w = q.split(d_part, dim=-<span class="hljs-number">1</span>)<br>    k_t, k_h, k_w = k.split(d_part, dim=-<span class="hljs-number">1</span>)<br>    <br>    <span class="hljs-comment"># 2. 定义局部应用 RoPE 的函数</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">apply_rope_to_part</span>(<span class="hljs-params">x, freqs</span>):<br>        <span class="hljs-comment"># freqs 包含拼接好的 cos 和 sin</span><br>        cos, sin = freqs.chunk(<span class="hljs-number">2</span>, dim=-<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> (x * cos) + (rotate_half(x) * sin)<br><br>    <span class="hljs-comment"># 3. 三个轴并行旋转</span><br>    q_out = torch.cat([<br>        apply_rope_to_part(q_t, freqs_t),<br>        apply_rope_to_part(q_h, freqs_h),<br>        apply_rope_to_part(q_w, freqs_w)<br>    ], dim=-<span class="hljs-number">1</span>)<br>    <br>    k_out = torch.cat([<br>        apply_rope_to_part(k_t, freqs_t),<br>        apply_rope_to_part(k_h, freqs_h),<br>        apply_rope_to_part(k_w, freqs_w)<br>    ], dim=-<span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">return</span> q_out, k_out<br></code></pre></td></tr></table></figure><h1 id="CLip"><a href="#CLip" class="headerlink" title="CLip"></a>CLip</h1><h2 id="如何将变长的text和图片的特征长度一致？"><a href="#如何将变长的text和图片的特征长度一致？" class="headerlink" title="如何将变长的text和图片的特征长度一致？"></a>如何将变长的text和图片的特征长度一致？</h2><ul><li><p>文本端（Text Encoder）：<br>  文本经过分词（BPE）后，通常会固定一个长度（如 76）。在经过 Transformer 编码后，CLIP 并不使用所有 Token 的输出，而是提取 [EOS]位置的向量作为整句话的全局特征，（End of Sentence，通常是最后一个标签。attention机制中，EOS位置的向量会手机前面所有词汇的语义，信息向后流动）。</p></li><li><p>图像端（Image Encoder）：<br>  如果是 ViT (Vision Transformer)，它会像 BERT 一样使用一个特殊的 [CLS]Token 的输出来代表整张图片（Classification，因为ViT是双向的mask，所以在开始还是最后没有关系） 。</p></li></ul><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># requirements: torch, torchvision, transformers (可选)</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SimpleImageEncoder</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, out_dim=<span class="hljs-number">512</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-comment"># 简化：用一个小 CNN 或者直接线性投影</span><br>        <span class="hljs-variable language_">self</span>.backbone = nn.Sequential(<br>            nn.Flatten(),<br>            nn.Linear(<span class="hljs-number">3</span>*<span class="hljs-number">64</span>*<span class="hljs-number">64</span>, <span class="hljs-number">1024</span>),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">1024</span>, out_dim)<br>        )<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.backbone(x)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SimpleTextEncoder</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, vocab_size=<span class="hljs-number">30522</span>, embed_dim=<span class="hljs-number">512</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.embed = nn.Embedding(vocab_size, embed_dim)<br>        <span class="hljs-variable language_">self</span>.pool = nn.AdaptiveAvgPool1d(<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># 或者使用 pretrained BERT 的 CLS 向量</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, token_ids</span>):<br>        <span class="hljs-comment"># token_ids: (B, L)</span><br>        x = <span class="hljs-variable language_">self</span>.embed(token_ids)  <span class="hljs-comment"># (B, L, D)</span><br>        x = x.mean(dim=<span class="hljs-number">1</span>)          <span class="hljs-comment"># 简单池化 -&gt; (B, D)</span><br>        <span class="hljs-keyword">return</span> x<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ContrastiveModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim=<span class="hljs-number">512</span>, temp=<span class="hljs-number">0.07</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.img_enc = SimpleImageEncoder(out_dim=dim)<br>        <span class="hljs-variable language_">self</span>.txt_enc = SimpleTextEncoder(embed_dim=dim)<br>        <span class="hljs-variable language_">self</span>.temp = nn.Parameter(torch.tensor(temp))<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, images, token_ids</span>):<br>        img_feats = <span class="hljs-variable language_">self</span>.img_enc(images)         <span class="hljs-comment"># (B, D)</span><br>        txt_feats = <span class="hljs-variable language_">self</span>.txt_enc(token_ids)      <span class="hljs-comment"># (B, D)</span><br>        img_feats = F.normalize(img_feats, dim=-<span class="hljs-number">1</span>)<br>        txt_feats = F.normalize(txt_feats, dim=-<span class="hljs-number">1</span>)<br>        logits = torch.matmul(img_feats, txt_feats.t()) / <span class="hljs-variable language_">self</span>.temp.exp()  <span class="hljs-comment"># (B, B)</span><br>        labels = torch.arange(logits.size(<span class="hljs-number">0</span>), device=logits.device)<br>        loss_i = F.cross_entropy(logits, labels)              <span class="hljs-comment"># image-&gt;text</span><br>        loss_t = F.cross_entropy(logits.t(), labels)          <span class="hljs-comment"># text-&gt;image</span><br>        loss = (loss_i + loss_t) / <span class="hljs-number">2</span><br>        <span class="hljs-keyword">return</span> loss, logits<br></code></pre></td></tr></table></figure><h1 id="Norm"><a href="#Norm" class="headerlink" title="Norm"></a>Norm</h1><h2 id="LayerNorm"><a href="#LayerNorm" class="headerlink" title="LayerNorm"></a>LayerNorm</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LayerNorm</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, hidden_size, eps=<span class="hljs-number">1e-6</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.hidden_size = hidden_size  <span class="hljs-comment"># 隐藏状态的大小</span><br>        <span class="hljs-variable language_">self</span>.eps = eps  <span class="hljs-comment"># 用于数值稳定性的一个小值</span><br>        <br>        <span class="hljs-comment"># 初始化可学习的缩放和平移参数</span><br>        <span class="hljs-variable language_">self</span>.gamma = nn.Parameter(torch.ones(hidden_size))  <span class="hljs-comment"># 缩放参数，初始值为全1</span><br>        <span class="hljs-variable language_">self</span>.beta = nn.Parameter(torch.zeros(hidden_size))  <span class="hljs-comment"># 平移参数，初始值为全0</span><br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># x 形状: (batch_size, seq_len, hidden_size)</span><br>        <br>        <span class="hljs-comment"># 计算每个样本的均值和方差</span><br>        mean = x.mean(dim=-<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># 计算最后一个维度的均值，形状: (batch_size, seq_len, 1)</span><br>        variance = x.var(dim=-<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>, unbiased=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># 计算最后一个维度的方差，形状: (batch_size, seq_len, 1)</span><br>        <br>        <span class="hljs-comment"># 进行归一化</span><br>        x_normalized = (x - mean) / torch.sqrt(variance + <span class="hljs-variable language_">self</span>.eps)  <span class="hljs-comment"># 归一化，形状: (batch_size, seq_len, hidden_size)</span><br>        <br>        <span class="hljs-comment"># 应用缩放和平移参数</span><br>        output = <span class="hljs-variable language_">self</span>.gamma * x_normalized + <span class="hljs-variable language_">self</span>.beta  <span class="hljs-comment"># 形状: (batch_size, seq_len, hidden_size)</span><br>        <br>        <span class="hljs-keyword">return</span> output<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_layer_norm</span>():<br>    batch_size = <span class="hljs-number">2</span><br>    seq_len = <span class="hljs-number">4</span><br>    hidden_size = <span class="hljs-number">8</span><br>    <br>    <span class="hljs-comment"># 随机生成输入数据</span><br>    x = torch.randn(batch_size, seq_len, hidden_size)  <span class="hljs-comment"># (batch_size, seq_len, hidden_size)</span><br>    <br>    <span class="hljs-comment"># 创建 LayerNorm 模块</span><br>    layer_norm = LayerNorm(hidden_size)<br>    <br>    <span class="hljs-comment"># 计算 LayerNorm 输出</span><br>    output = layer_norm(x)<br>    <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Input shape:&quot;</span>, x.shape)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Output shape:&quot;</span>, output.shape)<br>    <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>test_layer_norm()<br><br><br><span class="hljs-comment"># KL散度</span><br><br>```python<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">manual_cross_entropy</span>(<span class="hljs-params">logits, target</span>):<br>    <span class="hljs-comment"># 第一步：计算 Softmax 概率</span><br>    probs = F.softmax(logits, dim=-<span class="hljs-number">1</span>)<br>    <br>    <span class="hljs-comment"># 第二步：对标签进行 One-hot 编码</span><br>    <span class="hljs-comment"># 比如 target [1] 变成 [0, 1, 0, 0, 0]</span><br>    one_hot = F.one_hot(target, num_classes=logits.shape[-<span class="hljs-number">1</span>])<br>    <br>    <span class="hljs-comment"># 第三步：计算 -log(p) 并只保留正确类别的那一项</span><br>    <span class="hljs-comment"># 加上 1e-9 是为了防止 log(0) 报错（数值稳定性）</span><br>    loss = -torch.<span class="hljs-built_in">sum</span>(one_hot * torch.log(probs + <span class="hljs-number">1e-9</span>), dim=-<span class="hljs-number">1</span>)<br>    <br>    <span class="hljs-comment"># 第四步：返回 Batch 的平均值</span><br>    <span class="hljs-keyword">return</span> loss.mean()<br><br><span class="hljs-comment"># 验证结果是否与官方一致</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Manual Loss: <span class="hljs-subst">&#123;manual_cross_entropy(logits, target).item()&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><h2 id="RMSNorm"><a href="#RMSNorm" class="headerlink" title="RMSNorm"></a>RMSNorm</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">RMSNorm</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, hidden_size, eps=<span class="hljs-number">1e-6</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.hidden_size = hidden_size<br>        <span class="hljs-variable language_">self</span>.eps = eps  <span class="hljs-comment"># 用于数值稳定性的一个小值</span><br>        <br>        <span class="hljs-comment"># 仅保留缩放参数 gamma，移除 beta</span><br>        <span class="hljs-variable language_">self</span>.gamma = nn.Parameter(torch.ones(hidden_size))  <span class="hljs-comment"># 初始化为全 1</span><br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># 计算均方根 (RMS)，不进行均值中心化</span><br>        rms = torch.sqrt(torch.mean(x.<span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>), dim=-<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>) + <span class="hljs-variable language_">self</span>.eps)  <span class="hljs-comment"># 平方后求均值，再开根</span><br>        <br>        <span class="hljs-comment"># 归一化：x / RMS</span><br>        x_normalized = x / rms  <span class="hljs-comment"># 不减去均值</span><br>        <br>        <span class="hljs-comment"># 仅应用 gamma 参数，无 beta</span><br>        output = <span class="hljs-variable language_">self</span>.gamma * x_normalized<br>        <br>        <span class="hljs-keyword">return</span> output<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_rms_norm</span>():  <span class="hljs-comment"># 修改测试函数名</span><br>    batch_size = <span class="hljs-number">2</span><br>    seq_len = <span class="hljs-number">4</span><br>    hidden_size = <span class="hljs-number">8</span><br>    <br>    x = torch.randn(batch_size, seq_len, hidden_size)<br>    rms_norm = RMSNorm(hidden_size)  <span class="hljs-comment"># 使用 RMSNorm 类</span><br>    output = rms_norm(x)<br>    <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Input shape:&quot;</span>, x.shape)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Output shape:&quot;</span>, output.shape)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Params:&quot;</span>, <span class="hljs-built_in">list</span>(rms_norm.parameters()))  <span class="hljs-comment"># 仅有一个参数 gamma</span><br>    <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    test_rms_norm()  <span class="hljs-comment"># 调用测试函数</span><br></code></pre></td></tr></table></figure><h2 id="BatchNorm"><a href="#BatchNorm" class="headerlink" title="BatchNorm"></a>BatchNorm</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BatchNorm</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, hidden_size, eps=<span class="hljs-number">1e-5</span>, momentum=<span class="hljs-number">0.1</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.hidden_size = hidden_size  <span class="hljs-comment"># 隐藏状态的大小</span><br>        <span class="hljs-variable language_">self</span>.eps = eps  <span class="hljs-comment"># 用于数值稳定性的一个小值</span><br>        <span class="hljs-variable language_">self</span>.momentum = momentum  <span class="hljs-comment"># 用于计算运行时均值和方差的动量</span><br>        <br>        <span class="hljs-comment"># 初始化可学习的缩放和平移参数</span><br>        <span class="hljs-variable language_">self</span>.gamma = nn.Parameter(torch.ones(hidden_size))  <span class="hljs-comment"># 缩放参数，初始值为全1</span><br>        <span class="hljs-variable language_">self</span>.beta = nn.Parameter(torch.zeros(hidden_size))  <span class="hljs-comment"># 平移参数，初始值为全0</span><br>        <br>        <span class="hljs-comment"># 初始化运行时均值和方差</span><br>        <span class="hljs-variable language_">self</span>.running_mean = torch.zeros(hidden_size)  <span class="hljs-comment"># 运行时均值，初始值为全0</span><br>        <span class="hljs-variable language_">self</span>.running_var = torch.ones(hidden_size)  <span class="hljs-comment"># 运行时方差，初始值为全1</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># x 形状: (batch_size, seq_len, hidden_size)</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.training:<br>            <span class="hljs-comment"># 计算当前批次的均值和方差</span><br>            batch_mean = x.mean(dim=(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>), keepdim=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># 计算前两个维度的均值，形状: (hidden_size)</span><br>            batch_var = x.var(dim=(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>), keepdim=<span class="hljs-literal">False</span>, unbiased=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># 计算前两个维度的方差，形状: (hidden_size)</span><br><br>            <span class="hljs-comment"># 更新运行时均值和方差</span><br>            <span class="hljs-variable language_">self</span>.running_mean = (<span class="hljs-number">1</span> - <span class="hljs-variable language_">self</span>.momentum) * <span class="hljs-variable language_">self</span>.running_mean + <span class="hljs-variable language_">self</span>.momentum * batch_mean<br>            <span class="hljs-variable language_">self</span>.running_var = (<span class="hljs-number">1</span> - <span class="hljs-variable language_">self</span>.momentum) * <span class="hljs-variable language_">self</span>.running_var + <span class="hljs-variable language_">self</span>.momentum * batch_var<br>            <br>            mean = batch_mean<br>            variance = batch_var<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># 使用运行时均值和方差</span><br>            mean = <span class="hljs-variable language_">self</span>.running_mean<br>            variance = <span class="hljs-variable language_">self</span>.running_var<br>        <br>        <span class="hljs-comment"># 进行归一化</span><br>        x_normalized = (x - mean) / torch.sqrt(variance + <span class="hljs-variable language_">self</span>.eps)  <span class="hljs-comment"># 归一化，形状: (batch_size, seq_len, hidden_size)</span><br>        <br>        <span class="hljs-comment"># 应用缩放和平移参数</span><br>        output = <span class="hljs-variable language_">self</span>.gamma * x_normalized + <span class="hljs-variable language_">self</span>.beta  <span class="hljs-comment"># 形状: (batch_size, seq_len, hidden_size)</span><br>        <br>        <span class="hljs-keyword">return</span> output<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_batch_norm</span>():<br>    batch_size = <span class="hljs-number">2</span><br>    seq_len = <span class="hljs-number">4</span><br>    hidden_size = <span class="hljs-number">8</span><br>    <br>    <span class="hljs-comment"># 随机生成输入数据</span><br>    x = torch.randn(batch_size, seq_len, hidden_size)  <span class="hljs-comment"># (batch_size, seq_len, hidden_size)</span><br>    <br>    <span class="hljs-comment"># 创建 BatchNorm 模块</span><br>    batch_norm = BatchNorm(hidden_size)<br>    <br>    <span class="hljs-comment"># 计算 BatchNorm 输出</span><br>    output = batch_norm(x)<br>    <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Input shape:&quot;</span>, x.shape)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Output shape:&quot;</span>, output.shape)<br>    <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>test_batch_norm()<br></code></pre></td></tr></table></figure><h1 id="Q-former"><a href="#Q-former" class="headerlink" title="Q-former"></a>Q-former</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><br></code></pre></td></tr></table></figure><h1 id="Lora"><a href="#Lora" class="headerlink" title="Lora"></a>Lora</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 逻辑示意：在 Attention 中应用 LoRA</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LoraLinear</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, weight, rank=<span class="hljs-number">8</span>, alpha=<span class="hljs-number">16</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.weight = weight <span class="hljs-comment"># 冻结的原始权重 (e.g., q_proj)</span><br>        <span class="hljs-variable language_">self</span>.lora_A = nn.Parameter(torch.randn(weight.size(<span class="hljs-number">1</span>), rank))<br>        <span class="hljs-variable language_">self</span>.lora_B = nn.Parameter(torch.zeros(rank, weight.size(<span class="hljs-number">0</span>)))<br>        <span class="hljs-variable language_">self</span>.scaling = alpha / rank<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># 原始路径 + LoRA 路径</span><br>        <span class="hljs-keyword">return</span> F.linear(x, <span class="hljs-variable language_">self</span>.weight) + (x @ <span class="hljs-variable language_">self</span>.lora_A @ <span class="hljs-variable language_">self</span>.lora_B) * <span class="hljs-variable language_">self</span>.scaling<br></code></pre></td></tr></table></figure><h1 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h1><h2 id="Binary-Cross-Entropy-and-Cross-Entropy"><a href="#Binary-Cross-Entropy-and-Cross-Entropy" class="headerlink" title="Binary Cross Entropy and Cross Entropy"></a>Binary Cross Entropy and Cross Entropy</h2><p>本质差别：BCE vs CE 的本质差异不在公式，而在你假设世界是“独立事件”还是“互斥选择”。</p><h3 id="Binary-Cross-Entropy-BCE-和-Categorical-Cross-Entropy-CE-CCE-的核心区别在于它们对“类别关系”的假设不同。"><a href="#Binary-Cross-Entropy-BCE-和-Categorical-Cross-Entropy-CE-CCE-的核心区别在于它们对“类别关系”的假设不同。" class="headerlink" title="Binary Cross Entropy (BCE) 和 Categorical Cross Entropy (CE&#x2F;CCE) 的核心区别在于它们对“类别关系”的假设不同。"></a>Binary Cross Entropy (BCE) 和 Categorical Cross Entropy (CE&#x2F;CCE) 的核心区别在于它们对“类别关系”的假设不同。</h3><ol><li>核心区别一览特性Binary Cross Entropy (BCE)Categorical Cross Entropy (CE)主要用途二分类或多标签分类多分类（单选）激活函数通常配合 Sigmoid通常配合 Softmax类别关系各类别相互独立（互不影响）各类别相互排斥（和为1）输出层节点1个（二分类）或 N个（多标签）N个（N代表类别总数）标签格式0 或 1（或多标签向量 [1, 0, 1]）One-hot 编码（如 [0, 0, 1]）</li><li>数学公式上的差异BCE (二元交叉熵)它衡量的是两个独立伯努利分布之间的差异。对于每一个样本，它考虑的是“是”与“否”：<br>$$Loss &#x3D; -[y \cdot \log(\hat{y}) + (1 - y) \cdot \log(1 - \hat{y})]$$<br>$y$ 是真实标签（0或1），$\hat{y}$ 是预测概率。CE (类别交叉熵)它衡量的是两个多项式分布之间的差异。它只关心真实类别那一项的预测概率：<br>$$Loss &#x3D; -\sum_{i&#x3D;1}^{N} y_i \cdot \log(\hat{y}<em>i)$$<br>由于 $y_i$ 通常是 One-hot 编码（只有一项是1，其余是0），所以这个公式实际上简化为：$- \log(\hat{p}</em>{true_class})$。</li></ol><h3 id="BCE-Code"><a href="#BCE-Code" class="headerlink" title="BCE Code"></a>BCE Code</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">binary_cross_entropy</span>(<span class="hljs-params">y_true, y_pred</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    计算二元交叉熵损失（需配合 Sigmoid 使用）</span><br><span class="hljs-string">    :param y_true: 二分类的真实标签（0 或 1），形状 (n_samples, n_classes)</span><br><span class="hljs-string">    :param y_pred: 模型输出的 logits，形状 (n_samples, n_classes)</span><br><span class="hljs-string">    :return: 标量损失值</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 应用 Sigmoid 将 logits 转换为概率</span><br>    sigmoid_output = <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.exp(-y_pred))<br>    <br>    <span class="hljs-comment"># 避免 log(0) 导致的数值问题</span><br>    epsilon = <span class="hljs-number">1e-7</span><br>    clipped = np.clip(sigmoid_output, epsilon, <span class="hljs-number">1</span> - epsilon)<br>    <br>    <span class="hljs-comment"># 计算每个样本每个类别的损失</span><br>    loss_per_element = - (y_true * np.log(clipped) + (<span class="hljs-number">1</span> - y_true) * np.log(<span class="hljs-number">1</span> - clipped))<br>    <br>    <span class="hljs-comment"># 对所有元素取平均损失</span><br>    <span class="hljs-keyword">return</span> np.mean(loss_per_element)<br><br><span class="hljs-comment"># 示例用法（两个样本，三分类多标签问题）</span><br>y_true = np.array([[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]])  <span class="hljs-comment"># 多标签真实值</span><br>y_pred = np.array([[<span class="hljs-number">2.0</span>, <span class="hljs-number">1.0</span>, -<span class="hljs-number">1.0</span>], [<span class="hljs-number">0.5</span>, <span class="hljs-number">3.0</span>, -<span class="hljs-number">0.5</span>]])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;BCE Loss: <span class="hljs-subst">&#123;binary_cross_entropy(y_true, y_pred):<span class="hljs-number">.4</span>f&#125;</span>&quot;</span>)  <span class="hljs-comment"># 输出 0.1955</span><br></code></pre></td></tr></table></figure><h3 id="CE-Code"><a href="#CE-Code" class="headerlink" title="CE Code"></a>CE Code</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cross_entropy</span>(<span class="hljs-params">y_true, y_pred</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    计算交叉熵损失（需配合 Softmax 使用），带数值稳定处理</span><br><span class="hljs-string">    :param y_true: one-hot 编码的真实标签，形状 (n_samples, n_classes)</span><br><span class="hljs-string">    :param y_pred: 模型输出的 logits，形状 (n_samples, n_classes)</span><br><span class="hljs-string">    :return: 标量损失值</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 数值稳定处理：减去最大值防止指数爆炸</span><br>    exps = np.exp(y_pred - np.<span class="hljs-built_in">max</span>(y_pred, axis=<span class="hljs-number">1</span>, keepdims=<span class="hljs-literal">True</span>))<br>    softmax_output = exps / np.<span class="hljs-built_in">sum</span>(exps, axis=<span class="hljs-number">1</span>, keepdims=<span class="hljs-literal">True</span>)<br>    <br>    <span class="hljs-comment"># 避免 log(0) 导致数值问题</span><br>    epsilon = <span class="hljs-number">1e-7</span><br>    clipped = np.clip(softmax_output, epsilon, <span class="hljs-number">1</span> - epsilon)<br>    <br>    <span class="hljs-comment"># 只计算真实类别对应的损失</span><br>    n_samples = y_true.shape[<span class="hljs-number">0</span>]<br>    log_likelihood = -np.log(clipped[<span class="hljs-built_in">range</span>(n_samples), y_true.argmax(axis=<span class="hljs-number">1</span>)])<br>    <span class="hljs-keyword">return</span> np.mean(log_likelihood)<br><br><span class="hljs-comment"># 示例用法（三分类问题）</span><br>y_true = np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>], [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]])  <span class="hljs-comment"># one-hot 编码</span><br>y_pred = np.array([[<span class="hljs-number">2.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">0.1</span>], [<span class="hljs-number">0.5</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">0.2</span>]])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;CrossEntropy Loss: <span class="hljs-subst">&#123;cross_entropy(y_true, y_pred):<span class="hljs-number">.4</span>f&#125;</span>&quot;</span>)  <span class="hljs-comment"># 输出 0.3184</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>原理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Evidence Lower Bound 推导与解释</title>
    <link href="/2025/12/20/%E8%BF%9E%E7%BB%AD%E6%80%A7%E6%96%B9%E7%A8%8B%E4%B8%8B%E7%9A%84Flow%20Matching%E5%92%8CDiffusion/"/>
    <url>/2025/12/20/%E8%BF%9E%E7%BB%AD%E6%80%A7%E6%96%B9%E7%A8%8B%E4%B8%8B%E7%9A%84Flow%20Matching%E5%92%8CDiffusion/</url>
    
    <content type="html"><![CDATA[<h2 id="1-连续性方程"><a href="#1-连续性方程" class="headerlink" title="1. 连续性方程"></a>1. 连续性方程</h2><p>$$\frac{\partial p_t(x)}{\partial t} + \nabla \cdot (p_t(x) v_t(x)) &#x3D; 0$$<br>下是方程中各个变量的详细物理与数学定义：</p><h4 id="1-p-t-x-：时间相关的概率密度"><a href="#1-p-t-x-：时间相关的概率密度" class="headerlink" title="1. $p_t(x)$ ：时间相关的概率密度"></a>1. $p_t(x)$ ：时间相关的概率密度</h4><ul><li>定义： 在时刻 $t$，样本点位于位置 $x$ 的概率密度函数。</li><li>物理含义： $p_t(x)$ 在 $t$ 时刻 $x$ 处的流体密度。</li></ul><h4 id="2-v-t-x-：速度向量场-Vector-Field"><a href="#2-v-t-x-：速度向量场-Vector-Field" class="headerlink" title="2. $v_t(x)$ ：速度向量场 (Vector Field)"></a>2. $v_t(x)$ ：速度向量场 (Vector Field)</h4><ul><li>定义： 一个函数，它为空间中每一个坐标 $x$ 和时刻 $t$ 指定了一个速度向量。</li><li>物理含义： 它是流体的流速。它告诉位于 $x$ 的概率微元：在下一瞬间，你应该往哪个方向移动，移动多快。</li><li><strong>在 FM 中的角色： 神经网络 $v_\theta$ 学习的目标正是这个变量。</strong></li></ul><h4 id="3-p-t-x-v-t-x-流量密度-Flux-Density"><a href="#3-p-t-x-v-t-x-流量密度-Flux-Density" class="headerlink" title="3. $p_t(x) v_t(x)$ : 流量密度(Flux Density)"></a>3. $p_t(x) v_t(x)$ : 流量密度(Flux Density)</h4><ul><li>定义：单位时间内，穿过单位面积的概率质量</li></ul><h4 id="3-nabla-cdot-dots-：散度项-Divergence"><a href="#3-nabla-cdot-dots-：散度项-Divergence" class="headerlink" title="3. $\nabla \cdot (\dots)$ ：散度项 (Divergence)"></a>3. $\nabla \cdot (\dots)$ ：散度项 (Divergence)</h4><ul><li>数学定义假设向量场 $\mathbf{v} &#x3D; (v_1, v_2, \dots, v_n)$ ，散度记作 $\nabla \cdot \mathbf{v}$，计算公式为各分量对其对应坐标的<strong>偏导数之和</strong>：<br>$$\nabla \cdot \mathbf{v} &#x3D; \frac{\partial v_1}{\partial x_1} + \frac{\partial v_2}{\partial x_2} + \dots + \frac{\partial v_n}{\partial x_n}$$</li></ul><h4 id="4-frac-partial-p-t-x-partial-t-：时变项-Temporal-Rate-of-Change"><a href="#4-frac-partial-p-t-x-partial-t-：时变项-Temporal-Rate-of-Change" class="headerlink" title="4. $\frac{\partial p_t(x)}{\partial t}$ ：时变项 (Temporal Rate of Change)"></a>4. $\frac{\partial p_t(x)}{\partial t}$ ：时变项 (Temporal Rate of Change)</h4><ul><li>定义： 概率密度对时间的偏导数。</li><li>物理含义： 在固定位置 $x$，密度随时间的变化。</li></ul><h4 id="5-frac-partial-p-t-x-partial-t-：时变项-Temporal-Rate-of-Change"><a href="#5-frac-partial-p-t-x-partial-t-：时变项-Temporal-Rate-of-Change" class="headerlink" title="5. $\frac{\partial p_t(x)}{\partial t}$ ：时变项 (Temporal Rate of Change)"></a>5. $\frac{\partial p_t(x)}{\partial t}$ ：时变项 (Temporal Rate of Change)</h4><ul><li>定义： 对$x$的偏导，算子 $\nabla \cdot$ 作用于通量 $p_t(x) v_t(x)$。</li><li>物理含义： 描述流体在某一点是发散还是汇聚。 $\nabla \cdot (p_t v_t)$ 计算的是单位时间内从 $x$ 点流出的净概率质量。</li><li>通量 (Flux)： 括号内的 $p_t(x) v_t(x)$ 代表概率流的强度（密度 $\times$ 速度）。</li></ul><h2 id="2-Flow-matching"><a href="#2-Flow-matching" class="headerlink" title="2. Flow matching"></a>2. Flow matching</h2><h2 id="3-Condition-Flow-Matching"><a href="#3-Condition-Flow-Matching" class="headerlink" title="3. Condition Flow Matching"></a>3. Condition Flow Matching</h2><h2 id="4-具体路径"><a href="#4-具体路径" class="headerlink" title="4. 具体路径"></a>4. 具体路径</h2><h2 id=""><a href="#" class="headerlink" title=""></a></h2><ol start="3"><li>直观理解：导航系统的例子想象你在开车从 A（ $x_0$ ）去 B（ $x_1$ ）。训练阶段： 我们观察成千上万次从 A 到 B 的行驶记录。每一时刻，车速都是由起点和终点决定的。推理阶段： 你是一台自动驾驶电脑。现在你被扔在了路中间的某个点 $x_t$。消除 $x_0$ 的意义： 你的传感器只能看到你现在的坐标 $x_t$。如果你不知道你当初是从哪个具体的车库（ $x_0$ ）出来的，你该怎么走？通过推导出的公式（如 VP 路径的公式），我们可以把“当初从哪来”的信息，转化为“现在在哪里”和“最终去哪里”的关系。公式中的 $x_t$ 项其实就代表了“你当前的位置”，它隐含了路径演化至今的状态。</li></ol>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>原理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
